"""
OMR Pipeline Visualizer
A4 tespiti, cevap bÃ¶lgesi yakÄ±nlaÅŸtÄ±rma ve bubble detection aÅŸamalarÄ±nÄ± ayrÄ± ayrÄ± gÃ¶rselleÅŸtirir
"""

import cv2
import numpy as np
import json
import sys
from pathlib import Path

# Config
TARGET_WIDTH = 1654
TARGET_HEIGHT = 2339

# Cevap bÃ¶lgesi oranlarÄ±
ROI_Y_START = 0.38
ROI_Y_END = 0.92
ROI_X_START = 0.04
ROI_X_END = 0.96

# Grid parametreleri
NUM_QUESTIONS = 15
GRID_COLS = 5
GRID_ROWS = 10
OPTIONS = ["A", "B", "C", "D"]

# Kalibrasyon verisini yÃ¼kle (varsa)
def load_calibration():
    """calibration.json dosyasÄ±nÄ± yÃ¼kle"""
    try:
        with open("calibration.json", "r") as f:
            data = json.load(f)
        # String key'leri integer'a Ã§evir
        calibration = {}
        for q_str, options in data.items():
            calibration[int(q_str)] = options
        return calibration
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"âš ï¸ Kalibrasyon yÃ¼kleme hatasÄ±: {e}")
        return None

# Perspective correction parametreleri
BLUR_KERNEL = (5, 5)
CANNY_LOW = 50
CANNY_HIGH = 150


def order_points(pts):
    """DÃ¶rt kÃ¶ÅŸe noktasÄ±nÄ± sÄ±rala: sol-Ã¼st, saÄŸ-Ã¼st, saÄŸ-alt, sol-alt"""
    rect = np.zeros((4, 2), dtype="float32")
    
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # Sol-Ã¼st
    rect[2] = pts[np.argmax(s)]  # SaÄŸ-alt
    
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # SaÄŸ-Ã¼st
    rect[3] = pts[np.argmax(diff)]  # Sol-alt
    
    return rect


def find_paper_contour(image):
    """GÃ¶rÃ¼ntÃ¼de kaÄŸÄ±t sÄ±nÄ±rlarÄ±nÄ± bul"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, BLUR_KERNEL, 0)
    edges = cv2.Canny(blurred, CANNY_LOW, CANNY_HIGH)
    
    kernel = np.ones((3, 3), np.uint8)
    edges = cv2.dilate(edges, kernel, iterations=2)
    
    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return None
    
    contours = sorted(contours, key=cv2.contourArea, reverse=True)
    
    approx_factors = [0.02, 0.03, 0.04, 0.05, 0.01]
    
    for contour in contours[:5]:
        area = cv2.contourArea(contour)
        image_area = image.shape[0] * image.shape[1]
        
        if area < image_area * 0.1:
            continue
        
        for factor in approx_factors:
            peri = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, factor * peri, True)
            
            if len(approx) == 4:
                return approx.reshape(4, 2)
    
    return None


def correct_perspective(image, corners):
    """Perspektif dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygula"""
    rect = order_points(corners.astype("float32"))
    
    dst = np.array([
        [0, 0],
        [TARGET_WIDTH - 1, 0],
        [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],
        [0, TARGET_HEIGHT - 1]
    ], dtype="float32")
    
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (TARGET_WIDTH, TARGET_HEIGHT))
    
    return warped


def visualize_pipeline(image_path, output_dir="output"):
    """
    OMR pipeline'Ä± gÃ¶rselleÅŸtir ve aÅŸamalarÄ± ayrÄ± ayrÄ± kaydet
    
    Args:
        image_path: GiriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼ yolu
        output_dir: Ã‡Ä±kÄ±ÅŸ klasÃ¶rÃ¼
    """
    # Ã‡Ä±kÄ±ÅŸ klasÃ¶rÃ¼nÃ¼ oluÅŸtur
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
    print(f"ğŸ“¸ GÃ¶rÃ¼ntÃ¼ yÃ¼kleniyor: {image_path}")
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"âŒ HATA: GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi: {image_path}")
        return False
    
    # ============================================================
    # AÅAMA 1: A4 KAÄIT TESPÄ°TÄ° VE PERSPEKTÄ°F DÃœZELTÄ°LMESÄ°
    # ============================================================
    print("\n" + "="*60)
    print("AÅAMA 1: A4 KAÄIT TESPÄ°TÄ°")
    print("="*60)
    
    # KaÄŸÄ±t kÃ¶ÅŸelerini bul
    corners = find_paper_contour(image)
    
    # Tespit edilen kÃ¶ÅŸeleri gÃ¶rselleÅŸtir
    stage1_visual = image.copy()
    
    if corners is not None:
        print("âœ… KaÄŸÄ±t kÃ¶ÅŸeleri bulundu!")
        
        # KÃ¶ÅŸeleri Ã§iz
        for i, corner in enumerate(corners):
            x, y = int(corner[0]), int(corner[1])
            cv2.circle(stage1_visual, (x, y), 15, (0, 255, 0), -1)
            cv2.putText(stage1_visual, f"{i+1}", (x-10, y-20),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        
        # SÄ±nÄ±rlarÄ± Ã§iz
        cv2.polylines(stage1_visual, [corners.astype(np.int32)], True, (0, 255, 0), 5)
        
        # Perspektif dÃ¼zeltme uygula
        warped = correct_perspective(image, corners)
    else:
        print("âš ï¸ KaÄŸÄ±t kÃ¶ÅŸeleri bulunamadÄ±, gÃ¶rÃ¼ntÃ¼ resize ediliyor...")
        warped = cv2.resize(image, (TARGET_WIDTH, TARGET_HEIGHT))
    
    # Ã‡IKTI 1: A4 tespit gÃ¶rÃ¼ntÃ¼sÃ¼
    output1 = output_path / "1_a4_detection.jpg"
    cv2.imwrite(str(output1), stage1_visual)
    print(f"ğŸ’¾ Kaydedildi: {output1}")
    
    # DÃ¼zeltilmiÅŸ gÃ¶rÃ¼ntÃ¼
    output1_corrected = output_path / "1_a4_corrected.jpg"
    cv2.imwrite(str(output1_corrected), warped)
    print(f"ğŸ’¾ Kaydedildi: {output1_corrected}")
    
    # ============================================================
    # AÅAMA 2: CEVAP BÃ–LGESÄ° YAKINLAÅTIRMA (ROI EXTRACTION)
    # ============================================================
    print("\n" + "="*60)
    print("AÅAMA 2: CEVAP BÃ–LGESÄ° YAKINLAÅTIRMA")
    print("="*60)
    
    # Gri tonlama
    gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    
    # ROI koordinatlarÄ±
    roi_y1 = int(h * ROI_Y_START)
    roi_y2 = int(h * ROI_Y_END)
    roi_x1 = int(w * ROI_X_START)
    roi_x2 = int(w * ROI_X_END)
    
    print(f"ğŸ“ ROI KoordinatlarÄ±:")
    print(f"   X: {roi_x1} - {roi_x2} (geniÅŸlik: {roi_x2 - roi_x1}px)")
    print(f"   Y: {roi_y1} - {roi_y2} (yÃ¼kseklik: {roi_y2 - roi_y1}px)")
    
    # ROI'yi kes
    roi = gray[roi_y1:roi_y2, roi_x1:roi_x2]
    
    # ROI bÃ¶lgesini ana gÃ¶rÃ¼ntÃ¼de iÅŸaretle
    stage2_visual = warped.copy()
    cv2.rectangle(stage2_visual, (roi_x1, roi_y1), (roi_x2, roi_y2), (0, 255, 0), 8)
    cv2.putText(stage2_visual, "CEVAP BOLGESI", (roi_x1 + 20, roi_y1 - 20),
               cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)
    
    # Ã‡IKTI 2A: ROI iÅŸaretli tam gÃ¶rÃ¼ntÃ¼
    output2a = output_path / "2_answer_region_marked.jpg"
    cv2.imwrite(str(output2a), stage2_visual)
    print(f"ğŸ’¾ Kaydedildi: {output2a}")
    
    # Ã‡IKTI 2B: Sadece ROI (yakÄ±nlaÅŸtÄ±rÄ±lmÄ±ÅŸ)
    output2b = output_path / "2_answer_region_zoomed.jpg"
    roi_bgr = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)
    cv2.imwrite(str(output2b), roi_bgr)
    print(f"ğŸ’¾ Kaydedildi: {output2b}")
    
    # ============================================================
    # AÅAMA 3: BUBBLE DETECTION
    # ============================================================
    print("\n" + "="*60)
    print("AÅAMA 3: BUBBLE DETECTION")
    print("="*60)
    
    roi_h, roi_w = roi.shape
    
    # Kalibrasyon verÄ±sÄ±nÄ± yÃ¼kle
    calibration = load_calibration()
    
    if calibration:
        print(f"âœ… Kalibrasyon dosyasÄ± bulundu! ({len(calibration)} soru)")
        print(f"ğŸ“ Kalibre edilmiÅŸ koordinatlar kullanÄ±lÄ±yor...")
        use_calibration = True
    else:
        print(f"âš ï¸ Kalibrasyon dosyasÄ± yok, grid tabanlÄ± tespit kullanÄ±lÄ±yor...")
        use_calibration = False
        
        # Grid parametreleri
        col_width = roi_w / GRID_COLS
        row_height = roi_h / GRID_ROWS
        option_width = col_width / len(OPTIONS)
        
        print(f"ğŸ“Š Grid Parametreleri:")
        print(f"   SÃ¼tun geniÅŸliÄŸi: {col_width:.1f}px")
        print(f"   SatÄ±r yÃ¼ksekliÄŸi: {row_height:.1f}px")
        print(f"   ÅÄ±k geniÅŸliÄŸi: {option_width:.1f}px")
    
    # Debug gÃ¶rÃ¼ntÃ¼sÃ¼ oluÅŸtur
    stage3_visual = cv2.cvtColor(roi.copy(), cv2.COLOR_GRAY2BGR)
    
    # TÃ¼m bubble'larÄ± tespit et ve iÅŸaretle
    bubble_count = 0
    
    if use_calibration:
        # KALÄ°BRASYON TABANLI BUBBLE DETECTION
        for q_num in calibration.keys():
            for option in OPTIONS:
                if option in calibration[q_num]:
                    # Kalibre edilmiÅŸ koordinatlarÄ± al
                    x_center = calibration[q_num][option]["x"]
                    y_center = calibration[q_num][option]["y"]
                    
                    # Bubble Ã§apÄ± (ortalama 15-20 piksel)
                    bubble_radius = 10
                    
                    # Bubble bÃ¶lgesi
                    bx1 = max(0, x_center - bubble_radius)
                    bx2 = min(roi_w, x_center + bubble_radius)
                    by1 = max(0, y_center - bubble_radius)
                    by2 = min(roi_h, y_center + bubble_radius)
                    
                    bubble = roi[by1:by2, bx1:bx2]
                    
                    if bubble.size > 0:
                        avg_intensity = np.mean(bubble)
                        bubble_count += 1
                        
                        # Renk kodlu Ã§izim - MAVÄ° (kalibre edilmiÅŸ)
                        if avg_intensity < 200:
                            color = (255, 128, 0)  # Mavi - potansiyel iÅŸaretli
                            thickness = 2
                        else:
                            color = (200, 150, 100)  # AÃ§Ä±k mavi - boÅŸ
                            thickness = 1
                        
                        # Bubble dikdÃ¶rtgeni
                        cv2.rectangle(stage3_visual, (bx1, by1), (bx2, by2), color, thickness)
                        
                        # Intensity deÄŸeri
                        cv2.putText(stage3_visual, f"{int(avg_intensity)}", 
                                   (bx1 + 2, by1 + 12), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
            
            # Soru numarasÄ± (ilk ÅŸÄ±kkÄ±n yanÄ±na)
            if "A" in calibration[q_num]:
                x_pos = calibration[q_num]["A"]["x"] - 30
                y_pos = calibration[q_num]["A"]["y"] + 5
                cv2.putText(stage3_visual, f"S{q_num}", 
                           (x_pos, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        print(f"âœ… {bubble_count} bubble (KALÄ°BRE) tespit edildi")
        
        # Legend ekle
        legend_y = roi_h - 40
        cv2.rectangle(stage3_visual, (10, legend_y), (30, legend_y + 20), (255, 128, 0), 2)
        cv2.putText(stage3_visual, "Kalibre Edilmis", (35, legend_y + 15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 128, 0), 2)
    
    else:
        # GRÄ°D TABANLI BUBBLE DETECTION (FALLBACK)
        for q_num in range(1, NUM_QUESTIONS + 1):
            col = (q_num - 1) // GRID_ROWS
            row = (q_num - 1) % GRID_ROWS
            
            y_center = int((row + 0.5) * row_height)
            x_col_start = int(col * col_width)
            
            for opt_idx, option in enumerate(OPTIONS):
                x_option_center = int(x_col_start + (opt_idx + 0.5) * option_width)
                
                # Bubble boyutlarÄ±
                bubble_w = int(option_width * 0.4)
                bubble_h = int(row_height * 0.4)
                
                # Bubble bÃ¶lgesi
                bx1 = max(0, x_option_center - bubble_w // 2)
                bx2 = min(roi_w, x_option_center + bubble_w // 2)
                by1 = max(0, y_center - bubble_h // 2)
                by2 = min(roi_h, y_center + bubble_h // 2)
                
                bubble = roi[by1:by2, bx1:bx2]
                
                if bubble.size > 0:
                    avg_intensity = np.mean(bubble)
                    bubble_count += 1
                    
                    # Renk kodlu Ã§izim - YEÅÄ°L/GRÄ° (grid tabanlÄ±)
                    if avg_intensity < 200:
                        color = (0, 255, 0)  # YeÅŸil - potansiyel iÅŸaretli
                        thickness = 2
                    else:
                        color = (128, 128, 128)  # Gri - boÅŸ
                        thickness = 1
                    
                    # Bubble dikdÃ¶rtgeni
                    cv2.rectangle(stage3_visual, (bx1, by1), (bx2, by2), color, thickness)
                    
                    # Intensity deÄŸeri
                    cv2.putText(stage3_visual, f"{int(avg_intensity)}", 
                               (bx1 + 2, by1 + 12), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
            
            # Soru numarasÄ±
            cv2.putText(stage3_visual, f"S{q_num}", 
                       (x_col_start - 30, y_center + 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
        
        print(f"âœ… {bubble_count} bubble (GRID) tespit edildi")
        
        # Grid Ã§izgileri ekle
        for col in range(GRID_COLS + 1):
            x = int(col * col_width)
            cv2.line(stage3_visual, (x, 0), (x, roi_h), (255, 0, 255), 1)
        
        for row in range(GRID_ROWS + 1):
            y = int(row * row_height)
            cv2.line(stage3_visual, (0, y), (roi_w, y), (255, 0, 255), 1)
        
        # Legend ekle
        legend_y = roi_h - 40
        cv2.rectangle(stage3_visual, (10, legend_y), (30, legend_y + 20), (0, 255, 0), 2)
        cv2.putText(stage3_visual, "Grid Tabanli (kalibre edin!)", (35, legend_y + 15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    # Ã‡IKTI 3: Bubble detection gÃ¶rÃ¼ntÃ¼sÃ¼
    output3 = output_path / "3_bubble_detection.jpg"
    cv2.imwrite(str(output3), stage3_visual)
    print(f"ğŸ’¾ Kaydedildi: {output3}")
    
    # ============================================================
    # Ã–ZET
    # ============================================================
    print("\n" + "="*60)
    print("âœ¨ TÃœM AÅAMALAR TAMAMLANDI!")
    print("="*60)
    print(f"\nğŸ“ Ã‡Ä±ktÄ± dosyalarÄ± ({output_dir}/):")
    print(f"   1ï¸âƒ£  1_a4_detection.jpg        - A4 kaÄŸÄ±t tespiti (kÃ¶ÅŸeler iÅŸaretli)")
    print(f"   1ï¸âƒ£  1_a4_corrected.jpg        - Perspektif dÃ¼zeltilmiÅŸ gÃ¶rÃ¼ntÃ¼")
    print(f"   2ï¸âƒ£  2_answer_region_marked.jpg - Cevap bÃ¶lgesi iÅŸaretli")
    print(f"   2ï¸âƒ£  2_answer_region_zoomed.jpg - Cevap bÃ¶lgesi yakÄ±nlaÅŸtÄ±rÄ±lmÄ±ÅŸ")
    print(f"   3ï¸âƒ£  3_bubble_detection.jpg     - Bubble detection (tÃ¼m bubble'lar)")
    print()
    
    return True


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("KullanÄ±m: python omr_pipeline_visualizer.py <gÃ¶rÃ¼ntÃ¼_yolu> [Ã§Ä±kÄ±ÅŸ_klasÃ¶rÃ¼]")
        print("\nÃ–rnek:")
        print("  python omr_pipeline_visualizer.py test_form.png")
        print("  python omr_pipeline_visualizer.py test_form.png my_outputs")
        sys.exit(1)
    
    image_path = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else "output"
    
    success = visualize_pipeline(image_path, output_dir)
    
    if success:
        print("ğŸ‰ Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±!")
    else:
        print("âŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z oldu!")
        sys.exit(1)
