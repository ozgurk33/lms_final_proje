"""
OMR Adaptive Reader - Real-time Video Frame Processing
Herhangi bir optik formu okuyabilir, calibration gerektirmez.
CanlÄ± video stream iÃ§in optimize edilmiÅŸtir.
"""

import cv2
import numpy as np
import json
import sys
from pathlib import Path

# Config
TARGET_WIDTH = 800
TARGET_HEIGHT = 1100

# ROI - Cevap alanÄ± (formun alt kÄ±smÄ±)
ROI_Y_START = 0.50  # Ãœstten %50
ROI_Y_END = 0.95    # Alta kadar
ROI_X_START = 0.05  # Soldan %5
ROI_X_END = 0.95    # SaÄŸdan %5

# Bubble tespit parametreleri (kÃ¼Ã§Ã¼k bubble'lar iÃ§in optimize)
BUBBLE_MIN_RADIUS = 5
BUBBLE_MAX_RADIUS = 15
FILL_THRESHOLD = 0.35  # %35 doluluk = iÅŸaretli
CIRCULARITY_THRESHOLD = 0.60  # Dairesellik eÅŸiÄŸi (biraz daha esnek)


def order_points(pts):
    """DÃ¶rt kÃ¶ÅŸe noktasÄ±nÄ± sÄ±rala: sol-Ã¼st, saÄŸ-Ã¼st, saÄŸ-alt, sol-alt"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # Sol-Ã¼st
    rect[2] = pts[np.argmax(s)]  # SaÄŸ-alt
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # SaÄŸ-Ã¼st
    rect[3] = pts[np.argmax(diff)]  # Sol-alt
    return rect


def find_paper_contour(image):
    """
    GÃ¶rÃ¼ntÃ¼de kaÄŸÄ±t sÄ±nÄ±rlarÄ±nÄ± bul (perspective.py'den alÄ±ndÄ±)
    Returns: 4 kÃ¶ÅŸe noktasÄ± veya None
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    
    kernel = np.ones((3, 3), np.uint8)
    edges = cv2.dilate(edges, kernel, iterations=2)
    
    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return None
    
    contours = sorted(contours, key=cv2.contourArea, reverse=True)
    approx_factors = [0.02, 0.03, 0.04, 0.05, 0.01]
    
    for contour in contours[:5]:
        area = cv2.contourArea(contour)
        image_area = image.shape[0] * image.shape[1]
        
        if area < image_area * 0.1:
            continue
        
        for factor in approx_factors:
            peri = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, factor * peri, True)
            
            if len(approx) == 4:
                return approx.reshape(4, 2)
    
    return None


def correct_perspective(image, corners):
    """Perspektif dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygula"""
    rect = order_points(corners.astype("float32"))
    
    dst = np.array([
        [0, 0],
        [TARGET_WIDTH - 1, 0],
        [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],
        [0, TARGET_HEIGHT - 1]
    ], dtype="float32")
    
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (TARGET_WIDTH, TARGET_HEIGHT))
    
    return warped


def detect_bubbles_adaptive(image):
    """
    Calibration olmadan bubble tespit et
    Contour analizi kullanarak bubble'larÄ± bul
    
    Returns: [(x, y, radius), ...] listesi
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # Otsu threshold ile bubble kenarlarÄ±nÄ± bul
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    
    # Morfolojik temizleme
    kernel = np.ones((2, 2), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # Contour bul
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    bubbles = []
    height, width = gray.shape
    
    for contour in contours:
        area = cv2.contourArea(contour)
        
        # Alan filtresi
        min_area = 3.14 * BUBBLE_MIN_RADIUS * BUBBLE_MIN_RADIUS
        max_area = 3.14 * BUBBLE_MAX_RADIUS * BUBBLE_MAX_RADIUS
        
        if area < min_area or area > max_area:
            continue
        
        # Dairesellik kontrolÃ¼
        perimeter = cv2.arcLength(contour, True)
        if perimeter == 0:
            continue
        
        circularity = 4 * 3.14159 * area / (perimeter * perimeter)
        
        if circularity < CIRCULARITY_THRESHOLD:
            continue
        
        # Daire merkezi ve yarÄ±Ã§apÄ±
        (cx, cy), radius = cv2.minEnclosingCircle(contour)
        cx, cy, radius = int(cx), int(cy), int(radius)
        
        if radius < BUBBLE_MIN_RADIUS or radius > BUBBLE_MAX_RADIUS:
            continue
        
        bubbles.append((cx, cy, radius))
    
    return bubbles


def organize_bubbles_to_grid(bubbles, image_shape):
    """
    Bubble'larÄ± grid sistemine yerleÅŸtir
    Otomatik olarak sÃ¼tun ve satÄ±rlarÄ± tespit et
    
    Returns: {question_num: [(x, y, r, option), ...]}
    """
    if not bubbles:
        return {}
    
    height, width = image_shape[:2]
    
    # Bubble'larÄ± y koordinatÄ±na gÃ¶re satÄ±rlara grupla
    bubbles_sorted_y = sorted(bubbles, key=lambda b: b[1])
    
    # SatÄ±rlarÄ± bul (y ekseninde yakÄ±n olan bubble'lar aynÄ± satÄ±r)
    rows = []
    current_row = [bubbles_sorted_y[0]]
    
    for i in range(1, len(bubbles_sorted_y)):
        prev_bubble = bubbles_sorted_y[i-1]
        curr_bubble = bubbles_sorted_y[i]
        
        # Y farkÄ± kÃ¼Ã§Ã¼kse aynÄ± satÄ±r
        y_diff = abs(curr_bubble[1] - prev_bubble[1])
        threshold = height * 0.03  # %3 tolerans
        
        if y_diff < threshold:
            current_row.append(curr_bubble)
        else:
            if len(current_row) >= 4:  # En az 4 bubble varsa geÃ§erli satÄ±r
                rows.append(current_row)
            current_row = [curr_bubble]
    
    # Son satÄ±rÄ± ekle
    if len(current_row) >= 4:
        rows.append(current_row)
    
    # Her satÄ±rdaki bubble'larÄ± x'e gÃ¶re sÄ±rala ve A,B,C,D ata
    organized = {}
    
    for row_idx, row_bubbles in enumerate(rows):
        # X'e gÃ¶re sÄ±rala
        row_bubbles_sorted = sorted(row_bubbles, key=lambda b: b[0])
        
        # Her 4 bubble bir soru
        num_questions_in_row = len(row_bubbles_sorted) // 4
        
        for q_offset in range(num_questions_in_row):
            question_bubbles = row_bubbles_sorted[q_offset*4:(q_offset+1)*4]
            
            if len(question_bubbles) == 4:
                question_num = row_idx * num_questions_in_row + q_offset + 1
                organized[question_num] = {
                    "A": question_bubbles[0],
                    "B": question_bubbles[1],
                    "C": question_bubbles[2],
                    "D": question_bubbles[3]
                }
    
    return organized


def analyze_bubble_fill(image, bubbles_grid):
    """
    Her bubble'Ä±n dolu olup olmadÄ±ÄŸÄ±nÄ± kontrol et
    
    Returns: {question_num: {option: is_filled, ...}}
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # Adaptive threshold
    thresh = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        15, 3
    )
    
    fill_data = {}
    
    for q_num, options in bubbles_grid.items():
        fill_data[q_num] = {}
        
        for option, (cx, cy, r) in options.items():
            # Daire iÃ§indeki pikselleri analiz et
            mask = np.zeros(thresh.shape, dtype=np.uint8)
            cv2.circle(mask, (cx, cy), max(1, r - 2), 255, -1)
            
            circle_pixels = cv2.bitwise_and(thresh, mask)
            total_pixels = np.sum(mask == 255)
            white_pixels = np.sum(circle_pixels == 255)
            
            fill_ratio = white_pixels / total_pixels if total_pixels > 0 else 0.0
            fill_data[q_num][option] = fill_ratio
    
    return fill_data


def extract_answers(fill_data):
    """
    Doluluk verilerinden cevaplarÄ± Ã§Ä±kar
    """
    answers = {}
    confidence = {}
    
    for q_num, options in fill_data.items():
        if not options:
            answers[q_num] = None
            confidence[q_num] = 0.0
            continue
        
        # En yÃ¼ksek doluluk oranÄ±na sahip ÅŸÄ±k
        max_option = max(options, key=options.get)
        max_fill = options[max_option]
        
        # EÅŸik kontrolÃ¼
        if max_fill < FILL_THRESHOLD:
            answers[q_num] = None
            confidence[q_num] = 0.0
            continue
        
        answers[q_num] = max_option
        confidence[q_num] = min(1.0, max_fill * 1.5)
    
    return answers, confidence


def draw_overlay(frame, corners, bubbles_grid, answers):
    """
    Video frame Ã¼zerine overlay Ã§iz
    - KaÄŸÄ±t kenarlarÄ± (yeÅŸil)
    - Tespit edilen bubble'lar
    - Cevaplar
    
    Returns: Overlay Ã§izilmiÅŸ frame
    """
    overlay = frame.copy()
    
    # KaÄŸÄ±t kenarlarÄ±nÄ± Ã§iz
    if corners is not None:
        corners_int = corners.astype(int)
        cv2.polylines(overlay, [corners_int], True, (0, 255, 0), 3)
        
        # KÃ¶ÅŸe noktalarÄ±nÄ± iÅŸaretle
        for i, corner in enumerate(corners_int):
            cv2.circle(overlay, tuple(corner), 8, (0, 0, 255), -1)
    
    return overlay


def process_frame(frame_path, output_path=None, debug=False):
    """
    Ana fonksiyon: Video frame'i iÅŸle
    
    Args:
        frame_path: Frame gÃ¶rÃ¼ntÃ¼sÃ¼ yolu
        output_path: Ã‡Ä±kÄ±ÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼ (overlay ile)
        debug: Debug modu
    
    Returns:
        {
            "success": bool,
            "paper_detected": bool,
            "corners": [[x,y], ...],
            "bubbles_count": int,
            "answers": {q_num: answer, ...},
            "confidence": {q_num: conf, ...},
            "summary": {...}
        }
    """
    # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
    frame = cv2.imread(str(frame_path))
    if frame is None:
        return {
            "success": False,
            "error": "Frame yÃ¼klenemedi",
            "paper_detected": False
        }
    
    # KaÄŸÄ±t tespiti
    corners = find_paper_contour(frame)
    
    if corners is None:
        return {
            "success": False,
            "error": "KaÄŸÄ±t tespit edilemedi",
            "paper_detected": False
        }
    
    # Perspektif dÃ¼zeltme
    corrected = correct_perspective(frame, corners)
    
    # ROI'yi Ã§Ä±kar (cevap bÃ¶lgesi)
    h, w = corrected.shape[:2]
    roi_y1 = int(h * ROI_Y_START)
    roi_y2 = int(h * ROI_Y_END)
    roi_x1 = int(w * ROI_X_START)
    roi_x2 = int(w * ROI_X_END)
    
    roi = corrected[roi_y1:roi_y2, roi_x1:roi_x2]
    
    if debug:
        cv2.imwrite("debug_roi.jpg", roi)
        print(f"DEBUG: ROI boyutu: {roi.shape}")
    
    # Bubble tespit (ROI Ã¼zerinde)
    bubbles = detect_bubbles_adaptive(roi)
    
    if debug:
        print(f"DEBUG: Tespit edilen bubble sayÄ±sÄ±: {len(bubbles)}")
    
    if len(bubbles) < 4:
        return {
            "success": False,
            "error": f"Yeterli bubble bulunamadÄ± ({len(bubbles)} bulunan, minimum 4 gerekli)",
            "paper_detected": True,
            "corners": corners.tolist(),
            "bubbles_count": len(bubbles)
        }
    
    # Grid organizasyonu
    bubbles_grid = organize_bubbles_to_grid(bubbles, roi.shape)
    
    if debug:
        print(f"DEBUG: Organize edilen soru sayÄ±sÄ±: {len(bubbles_grid)}")
    
    # Doluluk analizi
    fill_data = analyze_bubble_fill(roi, bubbles_grid)
    
    # Cevap Ã§Ä±karma
    answers, confidence = extract_answers(fill_data)
    
    # Overlay Ã§iz
    if output_path:
        overlay = draw_overlay(frame, corners, bubbles_grid, answers)
        cv2.imwrite(str(output_path), overlay)
    
    # Ã–zet
    answered_count = sum(1 for ans in answers.values() if ans is not None)
    total_questions = len(bubbles_grid)
    
    # Perspektif dÃ¼zeltilmiÅŸ gÃ¶rÃ¼ntÃ¼yÃ¼ base64'e Ã§evir
    import base64
    _, buffer = cv2.imencode('.jpg', corrected, [cv2.IMWRITE_JPEG_QUALITY, 85])
    corrected_base64 = base64.b64encode(buffer).decode('utf-8')
    
    return {
        "success": True,
        "paper_detected": True,
        "corners": corners.tolist(),
        "corrected_image_base64": corrected_base64,  # Yeni!
        "bubbles_count": len(bubbles),
        "questions_detected": total_questions,
        "answers": answers,
        "confidence": confidence,
        "summary": {
            "total": total_questions,
            "answered": answered_count,
            "blank": total_questions - answered_count
        }
    }


def main():
    if len(sys.argv) < 2:
        print("KullanÄ±m: python omr_adaptive_reader.py <frame_path> [output_path]")
        print("\nÃ–rnek:")
        print("  python omr_adaptive_reader.py test_form.png output_overlay.jpg")
        sys.exit(1)
    
    frame_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else "adaptive_output.jpg"
    
    print("=" * 60)
    print("OMR ADAPTIVE READER - Real-time Processing")
    print("=" * 60)
    print(f"ğŸ“¸ Frame: {frame_path}")
    print()
    
    result = process_frame(frame_path, output_path, debug=True)
    
    # Sonucu ekrana yazdÄ±r
    if not result["success"]:
        print(f"âŒ HATA: {result.get('error', 'Bilinmeyen hata')}")
        if result.get("paper_detected"):
            print(f"   KaÄŸÄ±t tespit edildi ama bubble tespit baÅŸarÄ±sÄ±z")
            print(f"   Bulunan bubble sayÄ±sÄ±: {result.get('bubbles_count', 0)}")
        sys.exit(1)
    
    print("âœ… Frame iÅŸleme baÅŸarÄ±lÄ±!")
    print(f"ğŸ“„ KaÄŸÄ±t tespit edildi (4 kÃ¶ÅŸe)")
    print(f"ğŸ¯ Bulunan bubble: {result['bubbles_count']}")
    print(f"â“ Tespit edilen soru: {result['questions_detected']}")
    print()
    
    # CevaplarÄ± gÃ¶ster
    print("CEVAPLAR:")
    print("-" * 60)
    for q_num in sorted(result['answers'].keys()):
        ans = result['answers'][q_num]
        conf = result['confidence'][q_num]
        
        if ans:
            print(f"  âœ“ Soru {q_num:2d}: {ans} (gÃ¼ven: {conf:.0%})")
        else:
            print(f"  â—‹ Soru {q_num:2d}: BOÅ")
    
    print("-" * 60)
    print(f"\nToplam: {result['summary']['total']} | "
          f"Cevaplanan: {result['summary']['answered']} | "
          f"BoÅŸ: {result['summary']['blank']}")
    
    # JSON kaydet
    json_output = frame_path.replace('.png', '_result.json').replace('.jpg', '_result.json')
    with open(json_output, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ SonuÃ§lar kaydedildi:")
    print(f"   - {output_path} (overlay)")
    print(f"   - {json_output} (JSON)")
    print()
    print("âœ… Ä°ÅŸlem tamamlandÄ±!")


if __name__ == "__main__":
    main()
